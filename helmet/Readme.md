这是一个名为 HELMET 的长文本语言模型评估基准项目。以下是主要特点：

1. **概述**
- HELMET 是一个全面的长文本语言模型评估基准
- 涵盖了 7 个不同类别的任务
- 设计用于评估模型在不同长度和复杂度下的表现

2. **主要功能**
- 提供了完整的评估代码框架
- 支持多种模型评估(包括本地模型和 API 模型如 OpenAI、Anthropic 等)
- 包含大约 34GB 的[[预处理数据集]]
- 支持 VLLM 加速推理

3. **支持的任务类别**
- 长文本问答(LongQA)
- 文本摘要(Summ) 
- 上下文学习(ICL)
- 信息检索(Recall)
- RAG 系统评估
- 段落重排序
- ALCE 评估

4. **使用方法**
- 通过 pip 安装依赖
- 下载数据集
- 使用配置文件运行评估
- 支持添加新的模型和任务

5. **特色**
- 提供了详细的评估结果
- 包含了任务间相关性分析
- 支持模型基准评估
- 提供了完整的 Slurm 脚本用于分布式评估

这是一个非常实用的工具,可以帮助研究人员全面评估长文本语言模型的性能。项目文档详细,使用简单,且支持扩展新的模型和任务。
